{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basketball challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import Basketball\n",
    "from Dataprocess import Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset processing\n",
    "dataset_path = 'data'\n",
    "save_path = 'cache'\n",
    "of_save_path = 'optics'\n",
    "pp_opt_flow = False\n",
    "resize = (50, 50)\n",
    "\n",
    "# Test train Parameter\n",
    "num_frames = 100\n",
    "split = 'training'\n",
    "\n",
    "\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Processing  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "process = Preprocess(dataset_path=dataset_path, \n",
    "                save_path=save_path, \n",
    "                of_save_path=of_save_path, \n",
    "                pp_opt_flow=pp_opt_flow, \n",
    "                resize=resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing at data\\training\\hit\\0\\view1\n",
      "Data saved at cache\\training\\hit\\0\\view1\n",
      "Data saved at optics\\training\\hit\\0\\view1\n",
      "Data processing at data\\training\\hit\\0\\view2\n",
      "Data saved at cache\\training\\hit\\0\\view2\n",
      "Data saved at optics\\training\\hit\\0\\view2\n",
      "Data processing at data\\training\\hit\\1\\view1\n",
      "Data saved at cache\\training\\hit\\1\\view1\n",
      "Data saved at optics\\training\\hit\\1\\view1\n",
      "Data processing at data\\training\\hit\\1\\view2\n",
      "Data saved at cache\\training\\hit\\1\\view2\n",
      "Data saved at optics\\training\\hit\\1\\view2\n",
      "Data processing at data\\training\\hit\\10\\view1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-1d1c50d5ba9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\D\\Study\\4th semester\\machine learning\\Dataprocess.py\u001b[0m in \u001b[0;36mprepare_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0mreturn_op_save_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mreturn_save_path\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mreturn_op_save_path\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__recursive_prepare_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__recursive_prepare_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\D\\Study\\4th semester\\machine learning\\Dataprocess.py\u001b[0m in \u001b[0;36m__recursive_prepare_data\u001b[1;34m(self, data_path)\u001b[0m\n\u001b[0;32m     62\u001b[0m                 \u001b[0mfilespath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubsubpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m                 \u001b[0msubsub_path_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__recursive_prepare_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubsubpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubsub_path_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__data_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubsub_path_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\D\\Study\\4th semester\\machine learning\\Dataprocess.py\u001b[0m in \u001b[0;36m__recursive_prepare_data\u001b[1;34m(self, data_path)\u001b[0m\n\u001b[0;32m     62\u001b[0m                 \u001b[0mfilespath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubsubpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m                 \u001b[0msubsub_path_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__recursive_prepare_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubsubpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubsub_path_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__data_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubsub_path_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\D\\Study\\4th semester\\machine learning\\Dataprocess.py\u001b[0m in \u001b[0;36m__recursive_prepare_data\u001b[1;34m(self, data_path)\u001b[0m\n\u001b[0;32m     62\u001b[0m                 \u001b[0mfilespath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubsubpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m                 \u001b[0msubsub_path_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__recursive_prepare_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubsubpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubsub_path_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__data_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubsub_path_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\D\\Study\\4th semester\\machine learning\\Dataprocess.py\u001b[0m in \u001b[0;36m__recursive_prepare_data\u001b[1;34m(self, data_path)\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0msubsub_path_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__recursive_prepare_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubsubpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubsub_path_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__data_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubsub_path_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfilespath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\D\\Study\\4th semester\\machine learning\\Dataprocess.py\u001b[0m in \u001b[0;36m__data_process\u001b[1;34m(self, subsubpath)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m#video = self.re_size(org_video, (360, 480)) # H x W\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_path\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mof_save_path\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m             \u001b[0mtransformed_video\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morg_video\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubsubpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m# returns without resize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpp_opt_flow\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformed_video\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubsubpath\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0msave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\D\\Study\\4th semester\\machine learning\\Dataprocess.py\u001b[0m in \u001b[0;36mimg_transform\u001b[1;34m(self, video, subsubpath, save)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mimg_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvideo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubsubpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mno_background_video\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove_background\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m         \u001b[0mresize_no_background_video\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mre_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_background_video\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\D\\Study\\4th semester\\machine learning\\Dataprocess.py\u001b[0m in \u001b[0;36mremove_background\u001b[1;34m(self, videos)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mremove_background\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvideos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__background_subtractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'median'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvideos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\D\\Study\\4th semester\\machine learning\\Dataprocess.py\u001b[0m in \u001b[0;36m__background_subtractor\u001b[1;34m(self, method, videos)\u001b[0m\n\u001b[0;32m    191\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No input tensor provided.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'median'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__meidan_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\D\\Study\\4th semester\\machine learning\\Dataprocess.py\u001b[0m in \u001b[0;36m__meidan_array\u001b[1;34m(self, video, rate)\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[0mbackground\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[0mforeground\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackground\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mvideo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m         \u001b[0mforeground\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mforeground\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mrate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m         \u001b[0mforeground\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mforeground\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[1;31m#Image.fromarray(foreground[0]).save('result.png')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "process.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Basketball\n",
    "dp = Basketball.Basketball(save_path, num_frames, split=split)\n",
    "dp.run('FFNN', testeverytrain=True, EPOCHS=EPOCHS)\n",
    "#dp.run('CNN3D', testeverytrain=True, EPOCHS=EPOCHS)\n",
    "#dp.run('CNN2DLSTM', testeverytrain=True, EPOCHS=EPOCHS)\n",
    "#dp.run('OPTICALCONV3D', testeverytrain=True, EPOCHS=EPOCHS, opticalpath=of_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#from IPython import display\n",
    "#import torchvision.transforms.functional as F\n",
    "#for batch, target in trainset:\n",
    "#    print(\"here is the \",target)\n",
    "#    view1 = batch[0]\n",
    "#    for idx, img in enumerate(view1):\n",
    "#        img1 = F.to_pil_image(img)\n",
    "#        display.clear_output(wait=True)\n",
    "#        display.display(img1.resize((320,240)), Image.NEAREST)\n",
    "#    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from IPython import display\n",
    "#import torchvision.transforms.functional as F\n",
    "#sets = DataLoader(dataset)\n",
    "#for bath, target in sets:\n",
    "#    print(\"here is the \",target)\n",
    "#    view1 = batch[0][0]\n",
    "#    for idx, img in enumerate(view1):\n",
    "#        img1 = F.to_pil_image(img)\n",
    "#        display.display(img1.resize((320,240)), Image.NEAREST)\n",
    "#        display.clear_output(wait=True)\n",
    "#    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Initialize weights\n",
    "image preprocessing\n",
    "normalizing the inputs\n",
    "regularizations\n",
    "\n",
    "inceptio v4\n",
    "inceptionv4\n",
    "resnet 101\n",
    "resnet 152\n",
    "\n",
    "1x1 convolution\n",
    "\n",
    "efficient architectures\n",
    "How do we obtain networks that are computationally and memory efficient\n",
    "enough to run on mobile devices, possibly with limited power supply?\n",
    "\n",
    "Width multiplier:\n",
    "Reduce the number of channels in each layer. This has been\n",
    "called width multiplier in „MobileNets: Efficient Convolutional Neural Networks\n",
    "for Mobile Vision Applications“.\n",
    "What is the effect on the computational complexity and on the parameters?\n",
    "\n",
    "resolution multiplier \n",
    "Reduce the resolution of the input image. This has been called\n",
    "resolution multiplier in „MobileNets: Efficient Convolutional Neural Networks for\n",
    "Mobile Vision Applications“.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Direct approach\n",
    "Model based approach\n",
    "Model and learning-based approach\n",
    "\n",
    "https://paperswithcode.com/paper/quo-vadis-action-recognition-a-new-model-and\n",
    "\n",
    "1. [Implemented] Feed Forward Neural Network (FFNN)\n",
    "View 1 and View 2 are concatenated side by side at first and each of the samples are then also concatenated. In this way a vector \n",
    "is formed which is then feed to the Feed Forward Neural Network(FFNN). Other variation could be going deep with multiple hidden layers\n",
    "2. CNN2  [Implemented]\n",
    "    view1->conv3d\n",
    "    view2->conv3d-------------> these are somehow combined and \n",
    "    optical(view1) -> conv3d--> flatted to predict 2 classes\n",
    "    optical(view2) -> conv3d\n",
    "3. CNN3 [Implemented] (use LTSM) -> https://github.com/HHTseng/video-classification\n",
    "    encode each frame with conv2d and send the output to be decoded to a lstm\n",
    "4. CNN4 [Implemented]\n",
    "    view1 and view2 and concatinated side by side and feed through the conv3d and flattened feed through linear layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Recursive Function to perform actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def recursive_prepare_data(data_path):\n",
    "    filespath = []\n",
    "    subdir = os.listdir(data_path)\n",
    "    for subpath in subdir:\n",
    "        subsubpath = os.path.join(data_path, subpath)\n",
    "        if os.path.isfile(subsubpath):\n",
    "            filespath.append(subsubpath)\n",
    "        else:\n",
    "            subsub_path_list = recursive_prepare_data(subsubpath)\n",
    "            if len(subsub_path_list) > 0:\n",
    "                # Use this for recursive action\n",
    "                #print(subsub_path_list)\n",
    "                pass\n",
    "    return filespath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='data/training/hit/0'\n",
    "recursive_prepare_data(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
