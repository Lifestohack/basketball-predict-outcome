{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "import serialize\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "results_files_name = serialize.get_all_results_names()\n",
    "results_files_name = [x for x in results_files_name if '.directory' not in x]\n",
    "results_files_name.reverse()\n",
    "out = widgets.Output()\n",
    "\n",
    "w = widgets.Dropdown(\n",
    "    options=results_files_name,\n",
    "    description='Result',\n",
    ")\n",
    "def update(filename):\n",
    "    data_from_csv = pd.read_csv(filename)\n",
    "    f,ax1 = plt.subplots(figsize =(15,10))\n",
    "    plt.title('Train/Test Performance',fontsize = 20,color='blue')\n",
    "    #plt.text(0,0,'Train',color='blue',fontsize = 18)\n",
    "    #plt.text(0,0,'Test',color='red',fontsize = 18)\n",
    "    sns.pointplot(x='epochs',y='trainloss', data=data_from_csv)\n",
    "    ax = sns.pointplot(x='epochs',y='testloss', color='red',data=data_from_csv)\n",
    "    for x,y,correct,total in zip(data_from_csv['epochs'],data_from_csv['testloss'],data_from_csv['correct'],data_from_csv['test']):\n",
    "        #change f'{z:.2f}' to str(z) if you want something simpler\n",
    "        ax.text(x-1,y+0.01,f'{(correct/total)*100:.2f}%',horizontalalignment='center',color='red',weight='light')\n",
    "    plt.xlabel('Epocs',fontsize = 15,color='blue')\n",
    "    plt.ylabel('Loss',fontsize = 15,color='blue')\n",
    "    display(w)\n",
    "    out\n",
    "    \n",
    "\n",
    "def on_change(change):\n",
    "    if change['name'] == 'value' and (change['new'] != change['old']):\n",
    "        clear_output()\n",
    "        update(change['new'])\n",
    "\n",
    "w.observe(on_change)\n",
    "update(results_files_name[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Basketball\n",
    "import time\n",
    "\n",
    "# *************IMPORTANT*********************\n",
    "# Following points are important.\n",
    "\n",
    "# Python memory management doesnot let explicitly freeing memory. \n",
    "# So even if loaded samples are not needed and therefore can be deleted, memory will not free up. So reading new samples will be slower as  \n",
    "# memory is still being used by old and garbage value. In Basketball class destroycache() function is implemented\n",
    "# to delete garbage memory but in python there is no guarantee when this will happen. \n",
    "# So please take care of following points\n",
    "\n",
    "# After background=True dataset is used then before background=False please clear memory otherwise \n",
    "# background=True frames will be returned from cache instead of background=False frames.\n",
    "\n",
    "# After training or validating one network please clear memory before training or validating next network. \n",
    "# If using Jupyter Notebook then by restarting.\n",
    "\n",
    "# After training for 30 frames don't train for higher than 30 frames but only lower frames.\n",
    "# So always train higher frames first and then lower frames\n",
    "\n",
    "# *************IMPORTANT*********************\n",
    "\n",
    "start_time = time.time()\n",
    "split = 'validation' #validation, training\n",
    "network = \"CNN3D\"\n",
    "background = True\n",
    "dp = Basketball.Basketball(network, width=128, height=128, split=split, trajectory=False, background=background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "dp.run(100, network, testeverytrain=True, EPOCHS=1, lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "if 'dp' in locals():\n",
    "    if dp is not None:\n",
    "        dp.destroycache()\n",
    "        del dp\n",
    "gc.collect()\n",
    "# please restart jupyter to clear memory. Python memory management\n",
    "# doensot allow to explicitly free memory\n",
    "# and this doesnot guarantee memory will be cleared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN3D    EPOCS    lr\n",
    "100      20       0.0001\n",
    "55       20       0.0001\n",
    "30       20       0.0001\n",
    "\n",
    "CNN2DLSTM    EPOCS    lr\n",
    "100      30       0.001\n",
    "55       20       0.001\n",
    "30       20       0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#from IPython import display\n",
    "#import torchvision.transforms.functional as F\n",
    "#for batch, target in trainset:\n",
    "#    print(\"here is the \",target)\n",
    "#    view1 = batch[0]\n",
    "#    for idx, img in enumerate(view1):\n",
    "#        img1 = F.to_pil_image(img)\n",
    "#        display.clear_output(wait=True)\n",
    "#        display.display(img1.resize((320,240)), Image.NEAREST)\n",
    "#    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from IPython import display\n",
    "#import torchvision.transforms.functional as F\n",
    "#sets = DataLoader(dataset)\n",
    "#for bath, target in sets:\n",
    "#    print(\"here is the \",target)\n",
    "#    view1 = batch[0][0]\n",
    "#    for idx, img in enumerate(view1):\n",
    "#        img1 = F.to_pil_image(img)\n",
    "#        display.display(img1.resize((320,240)), Image.NEAREST)\n",
    "#        display.clear_output(wait=True)\n",
    "#    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiprocessing of different samples. Please run it from any IDE. Uses all cores for faster multiprocessing\n",
    "# Two sets are created. One with background and one without background\n",
    "\n",
    "from DataMultiProcess import DataMultiProcess\n",
    "orgdata = '/run/media/luma/Blade/Users/lumi/basketball/dataset/orgdata'\n",
    "save_with_background = '/home/luma/Documents/mahinelearning/basketball/dataset/background'\n",
    "save_without_background = '/home/luma/Documents/mahinelearning/basketball/dataset/no_background'\n",
    "\n",
    "# Dataset with background \n",
    "DataMultiProcess(orgdata, save_with_background + '/128x128/samples', False, (64, 128), removebackground=False).start() # For CNN3D,  CNN2DLSTM and Two stream\n",
    "DataMultiProcess(orgdata, save_with_background + '/128x128_optic/samples', True, (64, 128), removebackground=False).start() # this needed for Two stream\n",
    "DataMultiProcess(orgdata, save_with_background +  '/48x48/samples', False, (24, 48), removebackground=False).start() # Run this for FFNN\n",
    "\n",
    "# Dataset without background \n",
    "DataMultiProcess(orgdata, save_without_background + '/128x128/samples', False, (64, 128), removebackground=True).start() # For CNN3D,  CNN2DLSTM and Two stream\n",
    "DataMultiProcess(orgdata, save_without_background + '/128x128_optic/samples', True, (64, 128), removebackground=True).start() # this needed for Two stream\n",
    "DataMultiProcess(orgdata, save_without_background + '/48x48/samples', False, (24, 48), removebackground=True).start() # Run this for FFNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize weights\n",
    "image preprocessing\n",
    "normalizing the inputs\n",
    "regularizations\n",
    "\n",
    "inceptio v4\n",
    "inceptionv4\n",
    "resnet 101\n",
    "resnet 152\n",
    "\n",
    "1x1 convolution\n",
    "\n",
    "efficient architectures\n",
    "How do we obtain networks that are computationally and memory efficient\n",
    "enough to run on mobile devices, possibly with limited power supply?\n",
    "\n",
    "Width multiplier:\n",
    "Reduce the number of channels in each layer. This has been\n",
    "called width multiplier in „MobileNets: Efficient Convolutional Neural Networks\n",
    "for Mobile Vision Applications“.\n",
    "What is the effect on the computational complexity and on the parameters?\n",
    "\n",
    "resolution multiplier \n",
    "Reduce the resolution of the input image. This has been called\n",
    "resolution multiplier in „MobileNets: Efficient Convolutional Neural Networks for\n",
    "Mobile Vision Applications“.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Direct approach\n",
    "Model based approach\n",
    "Model and learning-based approach\n",
    "\n",
    "https://paperswithcode.com/paper/quo-vadis-action-recognition-a-new-model-and\n",
    "\n",
    "1. [Implemented] Feed Forward Neural Network (FFNN)\n",
    "View 1 and View 2 are concatenated side by side at first and each of the samples are then also concatenated. In this way a vector \n",
    "is formed which is then feed to the Feed Forward Neural Network(FFNN). Other variation could be going deep with multiple hidden layers\n",
    "2. CNN2  [Implemented]\n",
    "    view1->conv3d\n",
    "    view2->conv3d-------------> these are somehow combined and \n",
    "    optical(view1) -> conv3d--> flatted to predict 2 classes\n",
    "    optical(view2) -> conv3d\n",
    "3. CNN3 [Implemented] (use LTSM) -> https://github.com/HHTseng/video-classification\n",
    "    encode each frame with conv2d and send the output to be decoded to a lstm\n",
    "4. CNN4 [Implemented]\n",
    "    view1 and view2 and concatinated side by side and feed through the conv3d and flattened feed through linear layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization: Adding a term to a loss function that penalizes for high weights. It tradies in some of the ability to fit the training data well for the ability to have a model generalize better to the data it has not seen before.\n",
    "E(Theta) = Sum of all inputs((target - input) ** 2 ) + (lamda/2*m) * weights**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generalization:\n",
    "    It is a technique to ensure that architecture as well as the training data are chosen in such as way that the network makes a good prediction during training.\n",
    "    1. Validate: Without validation it is impossible to judge whether my model is reasonable or starts overfitting the data. \n",
    "    2. Agumentation.\n",
    "    3. Ensemble learning\n",
    "    4. Dropout\n",
    "    5. Regularization with a penalty\n",
    "    6. Data augmentation\n",
    "    7. Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "\n",
    "data = torch.load(\"diwas.pt\")\n",
    "mean = np.array([0.5968847986774942, 0.595796225058005, 0.5962871697447794]).reshape(3,1,1)\n",
    "mean = mean.mean()\n",
    "std = np.array([0.261574085266821, 0.2626656457308586, 0.26264871624129915]).reshape(3,1,1)\n",
    "std = std.std()\n",
    "\n",
    "x_min = data.min()\n",
    "x_max = data.max()\n",
    "\n",
    "\n",
    "x = np.array(data)\n",
    "x = x.mean(0)\n",
    "\n",
    "y = scipy.stats.norm.pdf(x,mean,std)\n",
    "\n",
    "plt.plot(x,y, color='coral')\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.xlim(x_min,x_max)\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Normal Distribution')\n",
    "\n",
    "plt.savefig(\"normal_distribution.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x.mean(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "\n",
    "\n",
    "img = Image.open(\"dataset/background/data/samples/training/hit/0/00.png\") \n",
    "#data = torchvision.transforms.ToTensor()(img)\n",
    "data = np.array(img)\n",
    "data = torch.FloatTensor(data)\n",
    "\n",
    "mean = data.mean()\n",
    "std =  data.std()\n",
    "\n",
    "x = data.view(-1)\n",
    "\n",
    "x_min = data.min()\n",
    "x_max = data.max()\n",
    "\n",
    "\n",
    "\n",
    "y = scipy.stats.norm.pdf(x,mean,std)\n",
    "\n",
    "plt.plot(x,y, color='coral')\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.xlim(x_min,x_max)\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Normal Distribution')\n",
    "\n",
    "#plt.savefig(\"normal_distribution.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"dataset/background/data/samples/training/hit/0/00.png\") \n",
    "#data = torchvision.transforms.ToTensor()(img)\n",
    "data = np.array(img)\n",
    "data = torch.FloatTensor(data)\n",
    "\n",
    "mean = data.mean()\n",
    "std =  data.std()\n",
    "\n",
    "x = data.view(-1)\n",
    "\n",
    "x_min = data.min()\n",
    "x_max = data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\"asdf\",\"erw\",\"as\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "img = Image.open(\"dataset/background/data/samples/training/hit/0/00.png\")\n",
    "\n",
    "\n",
    "mu = 0\n",
    "variance = 1\n",
    "sigma = math.sqrt(variance)\n",
    "tensornormalize = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "mean = [0,0,0]\n",
    "std = [0,0,0]\n",
    "for i in range(data.shape[0]):\n",
    "    mean[i] = data[i].mean()\n",
    "    std[i] = data[i].std()\n",
    "        \n",
    "data = tensornormalize(img)\n",
    "tensornormalize = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Normalize(mean[0], std[0])\n",
    "])\n",
    "data = tensornormalize(data)\n",
    "#x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n",
    "x = data.flatten()\n",
    "plt.plot(x, stats.norm.pdf(x, mu, sigma))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0,0,0]\n",
    "std = [0,0,0]\n",
    "for i in range(data.shape[0]):\n",
    "    mean[i] = data[i].mean()\n",
    "    std[i] = data[i].std()\n",
    "print(std)\n",
    "print(mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
